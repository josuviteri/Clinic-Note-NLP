{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046519d3",
   "metadata": {},
   "source": [
    "Este proyecto tiene como objetivo desarrollar un modelo de procesamiento\n",
    "de lenguaje natural (NLP) capaz de generar resúmenes clínicos automáticos\n",
    "a partir de un dataset de alrededor de 1700 conversaciones entre doctores y\n",
    "sus pacientes, junto con los respectivos resúmenes y anotaciones.\n",
    "\n",
    "    Los objetivos de esta entrega 3 son:\n",
    "\n",
    "    1. Correciones de la entrega 2:\n",
    "\n",
    "Por ejemplo, ¿por qué lematizais? ¿Habéis analizado qué pasa con los word embeddings lematizado vs no-lematizado? Para embeddings la recomendación es no lematizar y con tf-idf habría que analizarlo con la tarea que queráis resolver. Además, ¿qué son lo que vosotros denomiáis tokens? Porque de 4367 palabras únicas no sé cómo salen 173,867 tokens.\n",
    "\n",
    "Por otro lado, el análisis de longitud está muy bien pero lo hacéis a nivel de palabra, no de token. De cara a siguientes entregas hacerlo también a nivel de token para ver si un BIOBert por ejemplo tiene contexto suficiente.\n",
    "\n",
    "\n",
    "\n",
    "    2. Definición de la tarea:\n",
    "¿Generación de resúmenes? ¿Clasificación por categorías? ¿Generar texto clínico? ¿Detectar entidades? \n",
    "Elegir 2.\n",
    "\n",
    "    3. Tareas Específicas de la entrega 3\n",
    "\n",
    "Para ello, se deberán usar técnicas tanto de Shallow ML (o ML tradicional), como algunos de los modelos de CNNs o Redes Recurrentes que hemos visto en clase.\n",
    "\n",
    "Comparar experimentos usando distintas métricas y optimizar los hiperparámetros.\n",
    "\n",
    "Usar atención, combinar features (no creo que aplique a nuestro problema)\n",
    "\n",
    "    Mínimos exigibles:\n",
    "• Dos técnicas de Shallow Learning utilizando técnicas de representación dispersa/sparse.\n",
    "• Dos técnicas de Deep Learning comparando diferentes tipos de embeddings y fine-tuneandolos dependiendo del caso. Ejemplos:\n",
    "• Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec “from scratch”\n",
    "• Embedding fine-tuneado durante el entrenamiento vs Embedding inicializado\n",
    "• Comparar al menos dos formas de embeddings de cada tipo:\n",
    "• Tradicionales: e.g., Bag-of-Words, TF-IDF, etc.\n",
    "• Semánticos No-Contextuales: e.g., Glove, FastText, Word2Vec, etc.\n",
    "• Contextuales: e.g., ELMo, BERT, Modelos pre-entrenados de Hugging-Face, etc."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
