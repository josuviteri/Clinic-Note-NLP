{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313a3f8d",
   "metadata": {},
   "source": [
    "Este proyecto tiene como objetivo desarrollar un modelo de procesamiento\n",
    "de lenguaje natural (NLP) capaz de generar resúmenes clínicos automáticos\n",
    "a partir de un dataset de alrededor de 1700 conversaciones entre doctores y\n",
    "sus pacientes, junto con los respectivos resúmenes y anotaciones.\n",
    "\n",
    "    Los objetivos de esta entrega 3 son:\n",
    "\n",
    "    1. Correciones de la entrega 2:\n",
    "\n",
    "Por ejemplo, ¿por qué lematizais? ¿Habéis analizado qué pasa con los word embeddings lematizado vs no-lematizado? Para embeddings la recomendación es no lematizar y con tf-idf habría que analizarlo con la tarea que queráis resolver. Además, ¿qué son lo que vosotros denomiáis tokens? Porque de 4367 palabras únicas no sé cómo salen 173,867 tokens.\n",
    "\n",
    "Por otro lado, el análisis de longitud está muy bien pero lo hacéis a nivel de palabra, no de token. De cara a siguientes entregas hacerlo también a nivel de token para ver si un BIOBert por ejemplo tiene contexto suficiente.\n",
    "\n",
    "\n",
    "\n",
    "    2. Definición de la tarea:\n",
    "Generación de resúmenes y clasificación del diagnóstico.\n",
    "\n",
    "    3. Tareas Específicas de la entrega 3\n",
    "\n",
    "Para ello, se deberán usar técnicas tanto de Shallow ML (o ML tradicional), como algunos de los modelos de CNNs o Redes Recurrentes que hemos visto en clase.\n",
    "\n",
    "Comparar experimentos usando distintas métricas y optimizar los hiperparámetros.\n",
    "\n",
    "Usar atención, combinar features (no creo que aplique a nuestro problema)\n",
    "\n",
    "    Mínimos exigibles:\n",
    "Dos técnicas de Shallow Learning utilizando técnicas de representación dispersa/sparse.\n",
    "\n",
    "Dos técnicas de Deep Learning comparando diferentes tipos de embeddings y fine-tuneandolos dependiendo del caso. Ejemplos:\n",
    "\n",
    "Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec “from scratch”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026ba47",
   "metadata": {},
   "source": [
    "Comparar al menos dos formas de embeddings de cada tipo:\n",
    "\n",
    "Tradicionales: e.g., Bag-of-Words, TF-IDF, etc.\n",
    "\n",
    "Semánticos No-Contextuales: e.g., Glove, FastText, Word2Vec, etc.\n",
    "\n",
    "Contextuales: e.g., ELMo, BERT, Modelos pre-entrenados de Hugging-Face, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a40b38",
   "metadata": {},
   "source": [
    "SHALLOW MACHINE LEARNING BASELINE\n",
    "TFIDF Vectorizer (unigrams + bigrams) + Logistic Regression\n",
    "\n",
    "Quick contextual embedding baseline: use sentence-transformers (all-MiniLM or biomedical variant) to encode dialogues and train a simple LogisticRegression classifier on those embeddings — strong and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbab11",
   "metadata": {},
   "source": [
    "Deep Learning Approach 1, FineTune BioClinicalBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f2b87",
   "metadata": {},
   "source": [
    "Deep Learning Approach 2, BiLSTM (or CNN) classifier using pretrained embeddings (FastText or your custom Word2Vec). Add attention on top of BiLSTM. This is a useful architecture to compare against BERT (lighter-weight).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72b2d3",
   "metadata": {},
   "source": [
    "Embedding experiments: train FastText on your corpus (or fine-tune pretrained FastText) and compare downstream performance vs pretrained FastText and vs contextual SBERT/BERT."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
