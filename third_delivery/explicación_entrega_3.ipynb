{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313a3f8d",
   "metadata": {},
   "source": [
    "Este archivo explica qué cambios se han hecho de la entrega anterior y qué se añade:\n",
    "\n",
    "    Los objetivos de esta entrega 3 son:\n",
    "\n",
    "    1. Corregir las sugerencias que recibimos de la entrega 2:\n",
    "\n",
    "***\"En general buen trabajo, habéis cubierto todo lo que se pedía. Sin embargo, por favor de cara a las siguientes entregas estructurar mejor la documentación y explicar lo que se está haciendo de manera más detallada.\"***\n",
    "\n",
    "- Estamos de acuerdo, en la entrega previa las explicaciones brillan por su ausencia, prestaremos especial atención en este aspecto.\n",
    "\n",
    "***\"Por ejemplo, ¿por qué lematizais? ¿Habéis analizado qué pasa con los word embeddings lematizado vs no-lematizado? Para embeddings la recomendación es no lematizar y con tf-idf habría que analizarlo con la tarea que queráis resolver.\"***  \n",
    "\n",
    "- Respecto a esto, vamos a repetir esta parte de la entrega 2 en el archivo \"rework_entrega_2.ipynb\".\n",
    "\n",
    "***\"Además, ¿qué son lo que vosotros denomiáis tokens? Porque de 4367 palabras únicas no sé cómo salen 173,867 tokens. Por otro lado, el análisis de longitud está muy bien pero lo hacéis a nivel de palabra, no de token. De cara a siguientes entregas hacerlo también a nivel de token para ver si un BIOBert por ejemplo tiene contexto suficiente.\"***\n",
    "\n",
    "- Lo hablamos en clase, al final había sido un malentendido, los 170,000 no eran tokens individuales sino los totales, individuales eran 4000. Simplemente por dejarlo aquí escrito pero ya estaba comentado.\n",
    "\n",
    "- Además se nos sugirió en clase usar un word2vec ya entrenado y compararlo con el nuestro, se supone que un modelo generlista puede ser mucho mejor que el nuestro modelo especializado, si es suficientemente grande.  \n",
    "\n",
    "***\"Por último, de cara a la siguiente entrega tenéis que definir bien qué vais a hacer: ¿Generación de resúmenes? ¿Clasificación por categorías? ¿Generar texto clínico? ¿Detectar entidades? Mi recomendación es que os centréis en dos. \"***\n",
    "\n",
    "Las dos tareas que hemos elegido con generación de resúmenes clínicos y clasificación por categoría.\n",
    "\n",
    "#####\n",
    "    En definitiva, haremos un rework de la segunda entrega, del \"second_delivery.ipynb\" en el archivo \"rework_entrega_2.ipynb\". Adaptado a las sugerencias.\n",
    "\n",
    "#####\n",
    "    2. Tareas Específicas de la entrega 3\n",
    "\n",
    "***Usar técnicas tanto de Shallow ML (o ML tradicional), como algunos de los modelos de CNNs o Redes Recurrentes que hemos visto en clase.***\n",
    "\n",
    "***Comparar experimentos usando distintas métricas y optimizar los hiperparámetros.***\n",
    "\n",
    "***Usar atención, combinar features*** (no creemos que aplique a nuestro problema)\n",
    "\n",
    "    Mínimos exigibles:\n",
    "Dos técnicas de Shallow Learning utilizando técnicas de representación dispersa/sparse.\n",
    "\n",
    "Dos técnicas de Deep Learning comparando diferentes tipos de embeddings y fine-tuneandolos dependiendo del caso. Ejemplos:\n",
    "\n",
    "Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec “from scratch”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026ba47",
   "metadata": {},
   "source": [
    "Comparar al menos dos formas de embeddings de cada tipo:\n",
    "\n",
    "Tradicionales: e.g., Bag-of-Words, TF-IDF, etc.\n",
    "\n",
    "Semánticos No-Contextuales: e.g., Glove, FastText, Word2Vec, etc.\n",
    "\n",
    "Contextuales: e.g., ELMo, BERT, Modelos pre-entrenados de Hugging-Face, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a40b38",
   "metadata": {},
   "source": [
    "SHALLOW MACHINE LEARNING BASELINE\n",
    "TFIDF Vectorizer (unigrams + bigrams) + Logistic Regression\n",
    "\n",
    "Quick contextual embedding baseline: use sentence-transformers (all-MiniLM or biomedical variant) to encode dialogues and train a simple LogisticRegression classifier on those embeddings — strong and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbab11",
   "metadata": {},
   "source": [
    "Deep Learning Approach 1, FineTune BioClinicalBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f2b87",
   "metadata": {},
   "source": [
    "Deep Learning Approach 2, BiLSTM (or CNN) classifier using pretrained embeddings (FastText or your custom Word2Vec). Add attention on top of BiLSTM. This is a useful architecture to compare against BERT (lighter-weight).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72b2d3",
   "metadata": {},
   "source": [
    "Embedding experiments: train FastText on your corpus (or fine-tune pretrained FastText) and compare downstream performance vs pretrained FastText and vs contextual SBERT/BERT."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
