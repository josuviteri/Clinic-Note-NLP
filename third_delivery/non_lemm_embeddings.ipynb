{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046519d3",
   "metadata": {},
   "source": [
    "Este proyecto tiene como objetivo desarrollar un modelo de procesamiento\n",
    "de lenguaje natural (NLP) capaz de generar resúmenes clínicos automáticos\n",
    "a partir de un dataset de alrededor de 1700 conversaciones entre doctores y\n",
    "sus pacientes, junto con los respectivos resúmenes y anotaciones.\n",
    "\n",
    "    Los objetivos de esta entrega 3 son:\n",
    "\n",
    "    1. Correciones de la entrega 2:\n",
    "\n",
    "Por ejemplo, ¿por qué lematizais? ¿Habéis analizado qué pasa con los word embeddings lematizado vs no-lematizado? Para embeddings la recomendación es no lematizar y con tf-idf habría que analizarlo con la tarea que queráis resolver. Además, ¿qué son lo que vosotros denomiáis tokens? Porque de 4367 palabras únicas no sé cómo salen 173,867 tokens.\n",
    "\n",
    "Por otro lado, el análisis de longitud está muy bien pero lo hacéis a nivel de palabra, no de token. De cara a siguientes entregas hacerlo también a nivel de token para ver si un BIOBert por ejemplo tiene contexto suficiente.\n",
    "\n",
    "\n",
    "\n",
    "    2. Definición de la tarea:\n",
    "Generación de resúmenes y clasificación del diagnóstico.\n",
    "\n",
    "    3. Tareas Específicas de la entrega 3\n",
    "\n",
    "Para ello, se deberán usar técnicas tanto de Shallow ML (o ML tradicional), como algunos de los modelos de CNNs o Redes Recurrentes que hemos visto en clase.\n",
    "\n",
    "Comparar experimentos usando distintas métricas y optimizar los hiperparámetros.\n",
    "\n",
    "Usar atención, combinar features (no creo que aplique a nuestro problema)\n",
    "\n",
    "    Mínimos exigibles:\n",
    "Dos técnicas de Shallow Learning utilizando técnicas de representación dispersa/sparse.\n",
    "\n",
    "Dos técnicas de Deep Learning comparando diferentes tipos de embeddings y fine-tuneandolos dependiendo del caso. Ejemplos:\n",
    "\n",
    "Word2Vec congelado vs Word2Vec fine-tuneado vs Word2Vec “from scratch”\n",
    "\n",
    "Embedding fine-tuneado durante el entrenamiento vs Embedding inicializado\n",
    "\n",
    "Comparar al menos dos formas de embeddings de cada tipo:\n",
    "\n",
    "Tradicionales: e.g., Bag-of-Words, TF-IDF, etc.\n",
    "\n",
    "Semánticos No-Contextuales: e.g., Glove, FastText, Word2Vec, etc.\n",
    "\n",
    "Contextuales: e.g., ELMo, BERT, Modelos pre-entrenados de Hugging-Face, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df727534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de librerías\n",
    "\n",
    "%pip install -q spacy gensim transformers torch tensorflow tensorflow-hub seaborn matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eafb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar modelo de idioma de spaCy\n",
    "\n",
    "#%pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462f5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import pickle\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP y embeddings\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f527bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/MTS-Dialog-TrainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cd12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "}\n",
    "\n",
    "def expand_contractions(text):\n",
    "    text = text.lower()\n",
    "    for c, repl in contraction_map.items():\n",
    "        text = re.sub(r\"\\b\" + re.escape(c) + r\"\\b\", repl, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95205d9",
   "metadata": {},
   "source": [
    "todos los modelos de embeddings tienen problemas con las palabras terminando en comas, y palabras abreviadas, por lo que las procesamos:\n",
    "\n",
    "\n",
    "  \"doc\"              \n",
    "  \"pat\"               \n",
    "  yes,               \n",
    "  guest_family:       \n",
    "  no,                \n",
    "  i'm                \n",
    "  it's               \n",
    "  yeah,             \n",
    "  that's              \n",
    "  don't              \n",
    "\n",
    "  yes, -> yes\n",
    "  \n",
    "  \n",
    "  I'm -> I am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18241918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s, lowercase=True):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    # Normalizar unicode\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    # Marcadores de quién habla\n",
    "    s = re.sub(r'\\bDoctor[:\\-]\\s*', ' <DOC> ', s, flags=re.I)\n",
    "    s = re.sub(r'\\bPatient[:\\-]\\s*', ' <PAT> ', s, flags=re.I)\n",
    "\n",
    "    # Expand contractions (do this before punctuation splitting)\n",
    "    s = expand_contractions(s)\n",
    "    # Separate punctuation by spaces so \"yes,\" -> \"yes ,\"\n",
    "    s = re.sub(r'([.,!?;:()\"\\[\\]])', r' \\1 ', s)\n",
    "\n",
    "    # Espacios\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    # Lowercase\n",
    "    if lowercase:\n",
    "        s = s.lower()\n",
    "    return s\n",
    "\n",
    "# Versión para ELMo (lowercase)\n",
    "df['dialog_clean'] = df['dialogue'].apply(lambda x: normalize_text(x, lowercase=True))\n",
    "\n",
    "# Versión para BIO/ClinicalBERT (manteniendo mayúsculas)\n",
    "df['dialog_clean_clinicBERT'] = df['dialogue'].apply(lambda x: normalize_text(x, lowercase=False))\n",
    "\n",
    "# Los resúmenes\n",
    "df['section_text_clean'] = df['section_text'].apply(lambda x: normalize_text(x, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc32b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 29.9% 497.2/1662.8MB downloadedCollecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz\n",
      "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz (119.1 MB)\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/119.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.5/119.1 MB 1.1 MB/s eta 0:01:46\n",
      "     ---------------------------------------- 1.0/119.1 MB 1.5 MB/s eta 0:01:18\n",
      "     ---------------------------------------- 1.3/119.1 MB 1.4 MB/s eta 0:01:23\n",
      "      --------------------------------------- 1.8/119.1 MB 1.6 MB/s eta 0:01:14\n",
      "      --------------------------------------- 1.8/119.1 MB 1.6 MB/s eta 0:01:14\n",
      "      --------------------------------------- 2.1/119.1 MB 1.3 MB/s eta 0:01:30\n",
      "      --------------------------------------- 2.4/119.1 MB 1.3 MB/s eta 0:01:32\n",
      "      --------------------------------------- 2.4/119.1 MB 1.3 MB/s eta 0:01:32\n",
      "      --------------------------------------- 2.9/119.1 MB 1.3 MB/s eta 0:01:28\n",
      "     - -------------------------------------- 3.1/119.1 MB 1.3 MB/s eta 0:01:29\n",
      "     - -------------------------------------- 3.4/119.1 MB 1.3 MB/s eta 0:01:29\n",
      "     - -------------------------------------- 3.7/119.1 MB 1.3 MB/s eta 0:01:28\n",
      "     - -------------------------------------- 3.9/119.1 MB 1.3 MB/s eta 0:01:32\n",
      "     - -------------------------------------- 3.9/119.1 MB 1.3 MB/s eta 0:01:32\n",
      "     - -------------------------------------- 4.2/119.1 MB 1.2 MB/s eta 0:01:34\n",
      "     - -------------------------------------- 4.5/119.1 MB 1.2 MB/s eta 0:01:34\n",
      "     - -------------------------------------- 4.5/119.1 MB 1.2 MB/s eta 0:01:34\n",
      "     - -------------------------------------- 5.0/119.1 MB 1.2 MB/s eta 0:01:37\n",
      "     - -------------------------------------- 5.0/119.1 MB 1.2 MB/s eta 0:01:37\n",
      "     - -------------------------------------- 5.2/119.1 MB 1.2 MB/s eta 0:01:38\n",
      "     - -------------------------------------- 5.2/119.1 MB 1.2 MB/s eta 0:01:38\n",
      "     - -------------------------------------- 5.5/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     - -------------------------------------- 5.8/119.1 MB 1.1 MB/s eta 0:01:44\n",
      "     - -------------------------------------- 5.8/119.1 MB 1.1 MB/s eta 0:01:44\n",
      "     -- ------------------------------------- 6.0/119.1 MB 1.1 MB/s eta 0:01:44\n",
      "     -- ------------------------------------- 6.3/119.1 MB 1.1 MB/s eta 0:01:43\n",
      "     -- ------------------------------------- 6.6/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     -- ------------------------------------- 6.6/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     -- ------------------------------------- 6.8/119.1 MB 1.1 MB/s eta 0:01:47\n",
      "     -- ------------------------------------- 7.3/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 7.6/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 7.9/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 7.9/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 7.9/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 7.9/119.1 MB 1.1 MB/s eta 0:01:42\n",
      "     -- ------------------------------------- 8.1/119.1 MB 1.0 MB/s eta 0:01:47\n",
      "     -- ------------------------------------- 8.4/119.1 MB 1.0 MB/s eta 0:01:47\n",
      "     -- ------------------------------------- 8.4/119.1 MB 1.0 MB/s eta 0:01:47\n",
      "     -- ------------------------------------- 8.7/119.1 MB 1.0 MB/s eta 0:01:49\n",
      "     --- ------------------------------------ 9.2/119.1 MB 1.0 MB/s eta 0:01:46\n",
      "     --- ------------------------------------ 9.4/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     --- ------------------------------------ 9.4/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     --- ------------------------------------ 9.4/119.1 MB 1.1 MB/s eta 0:01:45\n",
      "     --- ------------------------------------ 9.7/119.1 MB 1.0 MB/s eta 0:01:48\n",
      "     --- ----------------------------------- 10.0/119.1 MB 1.0 MB/s eta 0:01:47\n",
      "     --- ----------------------------------- 10.2/119.1 MB 1.0 MB/s eta 0:01:47\n",
      "     --- ----------------------------------- 10.5/119.1 MB 1.0 MB/s eta 0:01:46\n",
      "     --- ----------------------------------- 10.7/119.1 MB 1.0 MB/s eta 0:01:46\n",
      "     --- ----------------------------------- 11.0/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     --- ----------------------------------- 11.0/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     --- ----------------------------------- 11.5/119.1 MB 1.1 MB/s eta 0:01:43\n",
      "     --- ----------------------------------- 11.5/119.1 MB 1.1 MB/s eta 0:01:43\n",
      "     --- ----------------------------------- 11.8/119.1 MB 1.0 MB/s eta 0:01:44\n",
      "     --- ----------------------------------- 12.1/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     --- ----------------------------------- 12.1/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     ---- ---------------------------------- 12.3/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     ---- ---------------------------------- 12.3/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     ---- ---------------------------------- 12.8/119.1 MB 1.0 MB/s eta 0:01:44\n",
      "     ---- ---------------------------------- 12.8/119.1 MB 1.0 MB/s eta 0:01:44\n",
      "     ---- ---------------------------------- 13.1/119.1 MB 1.0 MB/s eta 0:01:45\n",
      "     ---- ---------------------------------- 13.6/119.1 MB 1.0 MB/s eta 0:01:42\n",
      "     ---- ---------------------------------- 13.9/119.1 MB 1.0 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 14.4/119.1 MB 1.1 MB/s eta 0:01:39\n",
      "     ---- ---------------------------------- 14.7/119.1 MB 1.1 MB/s eta 0:01:38\n",
      "     ---- ---------------------------------- 15.2/119.1 MB 1.1 MB/s eta 0:01:36\n",
      "     ----- --------------------------------- 15.7/119.1 MB 1.1 MB/s eta 0:01:34\n",
      "     ----- --------------------------------- 16.0/119.1 MB 1.1 MB/s eta 0:01:34\n",
      "     ----- --------------------------------- 16.5/119.1 MB 1.1 MB/s eta 0:01:32\n",
      "     ----- --------------------------------- 17.0/119.1 MB 1.1 MB/s eta 0:01:30\n",
      "     ----- --------------------------------- 17.6/119.1 MB 1.2 MB/s eta 0:01:28\n",
      "     ----- --------------------------------- 18.1/119.1 MB 1.2 MB/s eta 0:01:26\n",
      "     ----- --------------------------------- 18.1/119.1 MB 1.2 MB/s eta 0:01:26\n",
      "     ------ -------------------------------- 18.6/119.1 MB 1.2 MB/s eta 0:01:25\n",
      "     ------ -------------------------------- 19.4/119.1 MB 1.2 MB/s eta 0:01:23\n",
      "     ------ -------------------------------- 19.4/119.1 MB 1.2 MB/s eta 0:01:23\n",
      "     ------ -------------------------------- 19.9/119.1 MB 1.2 MB/s eta 0:01:22\n",
      "     ------ -------------------------------- 19.9/119.1 MB 1.2 MB/s eta 0:01:22\n",
      "     ------ -------------------------------- 20.7/119.1 MB 1.2 MB/s eta 0:01:20\n",
      "     ------- ------------------------------- 21.5/119.1 MB 1.3 MB/s eta 0:01:17\n",
      "     ------- ------------------------------- 22.3/119.1 MB 1.3 MB/s eta 0:01:15\n",
      "     ------- ------------------------------- 22.3/119.1 MB 1.3 MB/s eta 0:01:15\n",
      "     ------- ------------------------------- 22.3/119.1 MB 1.3 MB/s eta 0:01:15\n",
      "     ------- ------------------------------- 23.1/119.1 MB 1.3 MB/s eta 0:01:14\n",
      "     ------- ------------------------------- 23.9/119.1 MB 1.3 MB/s eta 0:01:12\n",
      "     -------- ------------------------------ 24.9/119.1 MB 1.4 MB/s eta 0:01:09\n",
      "     -------- ------------------------------ 25.2/119.1 MB 1.4 MB/s eta 0:01:09\n",
      "     -------- ------------------------------ 25.2/119.1 MB 1.4 MB/s eta 0:01:09\n",
      "     -------- ------------------------------ 26.0/119.1 MB 1.4 MB/s eta 0:01:08\n",
      "     -------- ------------------------------ 26.0/119.1 MB 1.4 MB/s eta 0:01:08\n",
      "     -------- ------------------------------ 26.5/119.1 MB 1.4 MB/s eta 0:01:08\n",
      "     -------- ------------------------------ 27.3/119.1 MB 1.4 MB/s eta 0:01:06\n",
      "     --------- ----------------------------- 28.0/119.1 MB 1.4 MB/s eta 0:01:04\n",
      "     --------- ----------------------------- 28.8/119.1 MB 1.4 MB/s eta 0:01:03\n",
      "     --------- ----------------------------- 28.8/119.1 MB 1.4 MB/s eta 0:01:03\n",
      "     --------- ----------------------------- 29.6/119.1 MB 1.5 MB/s eta 0:01:02\n",
      "     --------- ----------------------------- 29.6/119.1 MB 1.5 MB/s eta 0:01:02\n",
      "     ---------- ---------------------------- 30.7/119.1 MB 1.5 MB/s eta 0:01:00\n",
      "     ---------- ---------------------------- 31.2/119.1 MB 1.5 MB/s eta 0:00:59\n",
      "     ---------- ---------------------------- 32.0/119.1 MB 1.5 MB/s eta 0:00:58\n",
      "     ---------- ---------------------------- 32.8/119.1 MB 1.5 MB/s eta 0:00:57\n",
      "     ---------- ---------------------------- 33.6/119.1 MB 1.5 MB/s eta 0:00:56\n",
      "     ----------- --------------------------- 33.8/119.1 MB 1.6 MB/s eta 0:00:56\n",
      "     ----------- --------------------------- 34.3/119.1 MB 1.6 MB/s eta 0:00:55\n",
      "     ----------- --------------------------- 35.1/119.1 MB 1.6 MB/s eta 0:00:54\n",
      "     ----------- --------------------------- 35.9/119.1 MB 1.6 MB/s eta 0:00:52\n",
      "     ------------ -------------------------- 36.7/119.1 MB 1.6 MB/s eta 0:00:51\n",
      "     ------------ -------------------------- 37.7/119.1 MB 1.7 MB/s eta 0:00:50\n",
      "     ------------ -------------------------- 38.0/119.1 MB 1.6 MB/s eta 0:00:50\n",
      "     ------------ -------------------------- 38.8/119.1 MB 1.7 MB/s eta 0:00:49\n",
      "     ------------- ------------------------- 40.1/119.1 MB 1.7 MB/s eta 0:00:47\n",
      "     ------------- ------------------------- 40.1/119.1 MB 1.7 MB/s eta 0:00:47\n",
      "     ------------- ------------------------- 41.7/119.1 MB 1.7 MB/s eta 0:00:45\n",
      "     ------------- ------------------------- 41.9/119.1 MB 1.7 MB/s eta 0:00:45\n",
      "     ------------- ------------------------- 42.5/119.1 MB 1.7 MB/s eta 0:00:44\n",
      "     -------------- ------------------------ 43.3/119.1 MB 1.8 MB/s eta 0:00:44\n",
      "     -------------- ------------------------ 43.3/119.1 MB 1.8 MB/s eta 0:00:44\n",
      "     -------------- ------------------------ 43.8/119.1 MB 1.8 MB/s eta 0:00:44\n",
      "     -------------- ------------------------ 44.6/119.1 MB 1.8 MB/s eta 0:00:43\n",
      "     -------------- ------------------------ 45.1/119.1 MB 1.8 MB/s eta 0:00:42\n",
      "     -------------- ------------------------ 45.6/119.1 MB 1.8 MB/s eta 0:00:42\n",
      "     -------------- ------------------------ 45.6/119.1 MB 1.8 MB/s eta 0:00:42\n",
      "     --------------- ----------------------- 46.1/119.1 MB 1.8 MB/s eta 0:00:42\n",
      "     --------------- ----------------------- 46.7/119.1 MB 1.8 MB/s eta 0:00:41\n",
      "     --------------- ----------------------- 47.2/119.1 MB 1.8 MB/s eta 0:00:41\n",
      "     --------------- ----------------------- 47.2/119.1 MB 1.8 MB/s eta 0:00:41\n",
      "     --------------- ----------------------- 47.7/119.1 MB 1.8 MB/s eta 0:00:41\n",
      "     --------------- ----------------------- 48.5/119.1 MB 1.8 MB/s eta 0:00:40\n",
      "     --------------- ----------------------- 48.8/119.1 MB 1.8 MB/s eta 0:00:40\n",
      "     ---------------- ---------------------- 49.0/119.1 MB 1.8 MB/s eta 0:00:40\n",
      "     ---------------- ---------------------- 49.5/119.1 MB 1.8 MB/s eta 0:00:39\n",
      "     ---------------- ---------------------- 50.1/119.1 MB 1.8 MB/s eta 0:00:39\n",
      "     ---------------- ---------------------- 50.9/119.1 MB 1.8 MB/s eta 0:00:38\n",
      "     ---------------- ---------------------- 51.4/119.1 MB 1.8 MB/s eta 0:00:38\n",
      "     ---------------- ---------------------- 51.9/119.1 MB 1.8 MB/s eta 0:00:37\n",
      "     ----------------- --------------------- 52.7/119.1 MB 1.8 MB/s eta 0:00:37\n",
      "     ----------------- --------------------- 53.2/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ----------------- --------------------- 53.5/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ----------------- --------------------- 54.3/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ----------------- --------------------- 54.3/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ----------------- --------------------- 54.5/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ----------------- --------------------- 54.5/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ------------------ -------------------- 55.1/119.1 MB 1.8 MB/s eta 0:00:36\n",
      "     ------------------ -------------------- 55.6/119.1 MB 1.8 MB/s eta 0:00:35\n",
      "     ------------------ -------------------- 55.6/119.1 MB 1.8 MB/s eta 0:00:35\n",
      "     ------------------ -------------------- 56.1/119.1 MB 1.8 MB/s eta 0:00:35\n",
      "     ------------------ -------------------- 56.6/119.1 MB 1.8 MB/s eta 0:00:34\n",
      "     ------------------ -------------------- 57.1/119.1 MB 1.9 MB/s eta 0:00:34\n",
      "     ------------------ -------------------- 57.1/119.1 MB 1.9 MB/s eta 0:00:34\n",
      "     ------------------ -------------------- 57.7/119.1 MB 1.9 MB/s eta 0:00:34\n",
      "     ------------------ -------------------- 57.9/119.1 MB 1.9 MB/s eta 0:00:33\n",
      "     ------------------- ------------------- 58.5/119.1 MB 1.9 MB/s eta 0:00:33\n",
      "     ------------------- ------------------- 59.0/119.1 MB 1.9 MB/s eta 0:00:33\n",
      "     ------------------- ------------------- 59.0/119.1 MB 1.9 MB/s eta 0:00:33\n",
      "     ------------------- ------------------- 59.2/119.1 MB 1.9 MB/s eta 0:00:33\n",
      "     ------------------- ------------------- 59.8/119.1 MB 1.9 MB/s eta 0:00:32\n",
      "     ------------------- ------------------- 60.3/119.1 MB 1.9 MB/s eta 0:00:32\n",
      "     ------------------- ------------------- 60.3/119.1 MB 1.9 MB/s eta 0:00:32\n",
      "     ------------------- ------------------- 60.8/119.1 MB 1.9 MB/s eta 0:00:31\n",
      "     -------------------- ------------------ 61.3/119.1 MB 1.9 MB/s eta 0:00:31\n",
      "     -------------------- ------------------ 61.9/119.1 MB 1.9 MB/s eta 0:00:31\n",
      "     -------------------- ------------------ 62.4/119.1 MB 1.9 MB/s eta 0:00:30\n",
      "     -------------------- ------------------ 63.2/119.1 MB 2.0 MB/s eta 0:00:29\n",
      "     -------------------- ------------------ 63.7/119.1 MB 2.0 MB/s eta 0:00:29\n",
      "     -------------------- ------------------ 63.7/119.1 MB 2.0 MB/s eta 0:00:29\n",
      "     -------------------- ------------------ 64.0/119.1 MB 1.9 MB/s eta 0:00:29\n",
      "     -------------------- ------------------ 64.0/119.1 MB 1.9 MB/s eta 0:00:29\n",
      "     --------------------- ----------------- 64.5/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 64.5/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 64.7/119.1 MB 1.9 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 65.3/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 65.3/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 65.8/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 65.8/119.1 MB 2.0 MB/s eta 0:00:28\n",
      "     --------------------- ----------------- 66.3/119.1 MB 2.0 MB/s eta 0:00:27\n",
      "     --------------------- ----------------- 66.6/119.1 MB 2.0 MB/s eta 0:00:27\n",
      "     --------------------- ----------------- 67.1/119.1 MB 2.0 MB/s eta 0:00:27\n",
      "     ---------------------- ---------------- 67.4/119.1 MB 2.0 MB/s eta 0:00:27\n",
      "     ---------------------- ---------------- 67.9/119.1 MB 2.0 MB/s eta 0:00:26\n",
      "     ---------------------- ---------------- 67.9/119.1 MB 2.0 MB/s eta 0:00:26\n",
      "     ---------------------- ---------------- 68.4/119.1 MB 2.0 MB/s eta 0:00:26\n",
      "     ---------------------- ---------------- 68.9/119.1 MB 2.0 MB/s eta 0:00:25\n",
      "     ---------------------- ---------------- 69.5/119.1 MB 2.0 MB/s eta 0:00:25\n",
      "     ---------------------- ---------------- 69.7/119.1 MB 2.0 MB/s eta 0:00:25\n",
      "     ---------------------- ---------------- 70.0/119.1 MB 2.0 MB/s eta 0:00:25\n",
      "     ----------------------- --------------- 70.5/119.1 MB 2.0 MB/s eta 0:00:24\n",
      "     ----------------------- --------------- 71.0/119.1 MB 2.0 MB/s eta 0:00:24\n",
      "     ----------------------- --------------- 71.6/119.1 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------- --------------- 71.6/119.1 MB 2.1 MB/s eta 0:00:24\n",
      "     ----------------------- --------------- 72.1/119.1 MB 2.1 MB/s eta 0:00:23\n",
      "     ----------------------- --------------- 72.6/119.1 MB 2.1 MB/s eta 0:00:23\n",
      "     ----------------------- --------------- 73.1/119.1 MB 2.1 MB/s eta 0:00:23\n",
      "     ----------------------- --------------- 73.1/119.1 MB 2.1 MB/s eta 0:00:23\n",
      "     ------------------------ -------------- 73.4/119.1 MB 2.1 MB/s eta 0:00:23\n",
      "     ------------------------ -------------- 73.7/119.1 MB 2.1 MB/s eta 0:00:22\n",
      "     ------------------------ -------------- 74.2/119.1 MB 2.1 MB/s eta 0:00:22\n",
      "     ------------------------ -------------- 74.7/119.1 MB 2.1 MB/s eta 0:00:22\n",
      "     ------------------------ -------------- 75.0/119.1 MB 2.1 MB/s eta 0:00:21\n",
      "     ------------------------ -------------- 75.5/119.1 MB 2.1 MB/s eta 0:00:21\n",
      "     ------------------------ -------------- 76.0/119.1 MB 2.1 MB/s eta 0:00:21\n",
      "     ------------------------- ------------- 76.5/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 76.5/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 77.1/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 77.6/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 77.6/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 78.1/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 78.1/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 78.6/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 78.9/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     ------------------------- ------------- 78.9/119.1 MB 2.1 MB/s eta 0:00:20\n",
      "     -------------------------- ------------ 79.4/119.1 MB 2.1 MB/s eta 0:00:19\n",
      "     -------------------------- ------------ 80.0/119.1 MB 2.1 MB/s eta 0:00:19\n",
      "     -------------------------- ------------ 80.5/119.1 MB 2.1 MB/s eta 0:00:19\n",
      "     -------------------------- ------------ 81.0/119.1 MB 2.1 MB/s eta 0:00:19\n",
      "     -------------------------- ------------ 81.0/119.1 MB 2.1 MB/s eta 0:00:19\n",
      "     -------------------------- ------------ 81.8/119.1 MB 2.1 MB/s eta 0:00:18\n",
      "     -------------------------- ------------ 82.3/119.1 MB 2.1 MB/s eta 0:00:18\n",
      "     --------------------------- ----------- 82.8/119.1 MB 2.1 MB/s eta 0:00:18\n",
      "     --------------------------- ----------- 83.4/119.1 MB 2.1 MB/s eta 0:00:17\n",
      "     --------------------------- ----------- 83.4/119.1 MB 2.1 MB/s eta 0:00:17\n",
      "     --------------------------- ----------- 83.9/119.1 MB 2.1 MB/s eta 0:00:17\n",
      "     --------------------------- ----------- 84.7/119.1 MB 2.1 MB/s eta 0:00:17\n",
      "     --------------------------- ----------- 85.2/119.1 MB 2.1 MB/s eta 0:00:17\n",
      "     ---------------------------- ---------- 85.7/119.1 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------------- ---------- 86.5/119.1 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------------- ---------- 87.0/119.1 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------------- ---------- 87.8/119.1 MB 2.1 MB/s eta 0:00:15\n",
      "     ----------------------------- --------- 88.6/119.1 MB 2.1 MB/s eta 0:00:15\n",
      "     ----------------------------- --------- 89.1/119.1 MB 2.1 MB/s eta 0:00:14\n",
      "     ----------------------------- --------- 89.9/119.1 MB 2.2 MB/s eta 0:00:14\n",
      "     ----------------------------- --------- 89.9/119.1 MB 2.2 MB/s eta 0:00:14\n",
      "     ----------------------------- --------- 90.2/119.1 MB 2.1 MB/s eta 0:00:14\n",
      "     ----------------------------- --------- 91.0/119.1 MB 2.1 MB/s eta 0:00:14\n",
      "     ------------------------------ -------- 91.8/119.1 MB 2.1 MB/s eta 0:00:13\n",
      "     ------------------------------ -------- 91.8/119.1 MB 2.1 MB/s eta 0:00:13\n",
      "     ------------------------------ -------- 92.5/119.1 MB 2.1 MB/s eta 0:00:13\n",
      "     ------------------------------ -------- 93.6/119.1 MB 2.2 MB/s eta 0:00:12\n",
      "     ------------------------------ -------- 94.4/119.1 MB 2.2 MB/s eta 0:00:12\n",
      "     ------------------------------- ------- 95.4/119.1 MB 2.2 MB/s eta 0:00:11\n",
      "     ------------------------------- ------- 95.7/119.1 MB 2.2 MB/s eta 0:00:11\n",
      "     ------------------------------- ------- 96.7/119.1 MB 2.2 MB/s eta 0:00:11\n",
      "     ------------------------------- ------- 97.3/119.1 MB 2.2 MB/s eta 0:00:11\n",
      "     -------------------------------- ------ 98.6/119.1 MB 2.2 MB/s eta 0:00:10\n",
      "     -------------------------------- ------ 98.6/119.1 MB 2.2 MB/s eta 0:00:10\n",
      "     ------------------------------- ------ 100.1/119.1 MB 2.2 MB/s eta 0:00:09\n",
      "     -------------------------------- ----- 101.4/119.1 MB 2.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 102.2/119.1 MB 2.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 102.8/119.1 MB 2.2 MB/s eta 0:00:08\n",
      "     --------------------------------- ---- 103.5/119.1 MB 2.3 MB/s eta 0:00:07\n",
      "     --------------------------------- ---- 104.1/119.1 MB 2.2 MB/s eta 0:00:07\n",
      "     --------------------------------- ---- 104.9/119.1 MB 2.2 MB/s eta 0:00:07\n",
      "     ---------------------------------- --- 106.7/119.1 MB 2.3 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 107.7/119.1 MB 2.3 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 107.7/119.1 MB 2.3 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 108.8/119.1 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 108.8/119.1 MB 2.3 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 109.8/119.1 MB 2.3 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 110.9/119.1 MB 2.3 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 111.4/119.1 MB 2.3 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 112.2/119.1 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------------------------ - 113.2/119.1 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 114.6/119.1 MB 2.3 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 114.6/119.1 MB 2.3 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 115.3/119.1 MB 2.3 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 115.3/119.1 MB 2.3 MB/s eta 0:00:02\n",
      "     -------------------------------------  116.1/119.1 MB 2.3 MB/s eta 0:00:02\n",
      "     -------------------------------------  117.2/119.1 MB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  117.7/119.1 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  118.5/119.1 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  119.0/119.1 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 119.1/119.1 MB 2.4 MB/s  0:00:58\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting spacy<3.8.0,>=3.7.4 (from en_core_sci_md==0.5.4)\n",
      "  Downloading spacy-3.7.5-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.12)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Downloading thinc-8.2.5-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.4.3)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.2.6)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2025.11.12)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Downloading blis-0.7.11-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (8.3.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (14.2.0)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.20.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.1)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4)\n",
      "  Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\estib\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.3)\n",
      "Downloading spacy-3.7.5-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.1 MB 882.6 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/12.1 MB 1.4 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.8/12.1 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/12.1 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/12.1 MB 1.5 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/12.1 MB 1.3 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.4/12.1 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/12.1 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/12.1 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.1/12.1 MB 1.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 4.2/12.1 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.5/12.1 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 5.0/12.1 MB 1.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 5.2/12.1 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 5.5/12.1 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 6.0/12.1 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.6/12.1 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.3/12.1 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.1/12.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.2/12.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.2/12.1 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.2/12.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 2.0 MB/s  0:00:06\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading thinc-8.2.5-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.7 MB/s  0:00:00\n",
      "Downloading blis-0.7.11-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.6 MB 3.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.7/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 3.6 MB/s  0:00:01\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/15.8 MB 6.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.7/15.8 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.8 MB 9.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.8 MB 7.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.8 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 8.4 MB/s  0:00:01\n",
      "Using cached typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl (143 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: en_core_sci_md\n",
      "  Building wheel for en_core_sci_md (pyproject.toml): started\n",
      "  Building wheel for en_core_sci_md (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for en_core_sci_md: filename=en_core_sci_md-0.5.4-py3-none-any.whl size=119157975 sha256=d29623ab2b7fe69a4ce9e3c50f84d669cfe02465f819e982efc94bf82946bbfc\n",
      "  Stored in directory: c:\\users\\estib\\appdata\\local\\pip\\cache\\wheels\\d5\\01\\f2\\a4cc15346ad4d61907a67320d06bdfb9d5bf1b8e99004e9cd4\n",
      "Successfully built en_core_sci_md\n",
      "Installing collected packages: shellingham, numpy, marisa-trie, language-data, blis, typer, langcodes, thinc, spacy, en_core_sci_md\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.2.6\n",
      "\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "    Uninstalling numpy-2.2.6:\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ---- -----------------------------------  1/10 [numpy]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "  Attempting uninstall: blis\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "    Found existing installation: blis 1.3.3\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "    Uninstalling blis-1.3.3:\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "      Successfully uninstalled blis-1.3.3\n",
      "   ------------ ---------------------------  3/10 [language-data]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   ---------------- -----------------------  4/10 [blis]\n",
      "   -------------------- -------------------  5/10 [typer]\n",
      "  Attempting uninstall: thinc\n",
      "   -------------------- -------------------  5/10 [typer]\n",
      "    Found existing installation: thinc 8.3.10\n",
      "   -------------------- -------------------  5/10 [typer]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "    Uninstalling thinc-8.3.10:\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "      Successfully uninstalled thinc-8.3.10\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "  Attempting uninstall: spacy\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "    Found existing installation: spacy 3.8.11\n",
      "   ---------------------------- -----------  7/10 [thinc]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "    Uninstalling spacy-3.8.11:\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "      Successfully uninstalled spacy-3.8.11\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   -------------------------------- -------  8/10 [spacy]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ------------------------------------ ---  9/10 [en_core_sci_md]\n",
      "   ---------------------------------------- 10/10 [en_core_sci_md]\n",
      "\n",
      "Successfully installed blis-0.7.11 en_core_sci_md-0.5.4 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 numpy-1.26.4 shellingham-1.5.4 spacy-3.7.5 thinc-8.2.5 typer-0.20.0\n",
      "[==============------------------------------------] 30.0% 498.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\estib\\miniconda3\\envs\\nlp\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\estib\\miniconda3\\envs\\nlp\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\estib\\miniconda3\\envs\\nlp\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\estib\\miniconda3\\envs\\nlp\\Lib\\site-packages\\~lis'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script typer.exe is installed in 'c:\\Users\\estib\\miniconda3\\envs\\nlp\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\estib\\miniconda3\\envs\\nlp\\Lib\\site-packages\\~hinc'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script spacy.exe is installed in 'c:\\Users\\estib\\miniconda3\\envs\\nlp\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\estib\\miniconda3\\envs\\nlp\\Lib\\site-packages\\~pacy'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Embeddings (sin lemmatization)\n",
    "\n",
    "w2v = api.load(\"word2vec-google-news-300\")          # Word2Vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e6039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove = api.load(\"glove-wiki-gigaword-300\")        # GloVe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca6d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "ft = api.load(\"fasttext-wiki-news-subwords-300\")   # FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4473afd",
   "metadata": {},
   "source": [
    "SIN LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb8956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras/tokens: 152,400\n",
      "\n",
      "Vocabulario total: 5,367 palabras/tokens únic@s\n",
      "\n",
      "Modelo: Word2Vec (Google News)\n",
      "Palabras encontradas: 5,085/5,367 (94.75%)\n",
      "Tokens cubiertos: 109,237/152,400 (71.68%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  .                   : 10594 ocurrencias\n",
      "  ,                   :  6596 ocurrencias\n",
      "  <doc>               :  5810 ocurrencias\n",
      "  ?                   :  5113 ocurrencias\n",
      "  <pat>               :  4895 ocurrencias\n",
      "  a                   :  2121 ocurrencias\n",
      "  to                  :  2104 ocurrencias\n",
      "  and                 :  2033 ocurrencias\n",
      "  of                  :  1654 ocurrencias\n",
      "  :                   :   752 ocurrencias\n",
      "\n",
      "Modelo: GloVe (Wiki Gigaword)\n",
      "Palabras encontradas: 5,058/5,367 (94.24%)\n",
      "Tokens cubiertos: 140,039/152,400 (91.89%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  <doc>               :  5810 ocurrencias\n",
      "  <pat>               :  4895 ocurrencias\n",
      "  guest_family        :   560 ocurrencias\n",
      "  guest_clinician     :   119 ocurrencias\n",
      "  i'd                 :    91 ocurrencias\n",
      "  let's               :    65 ocurrencias\n",
      "  what's              :    57 ocurrencias\n",
      "  haven't             :    45 ocurrencias\n",
      "  i'll                :    44 ocurrencias\n",
      "  doctor_2            :    43 ocurrencias\n",
      "\n",
      "Modelo: FastText (Wiki News)\n",
      "Palabras encontradas: 5,085/5,367 (94.75%)\n",
      "Tokens cubiertos: 139,922/152,400 (91.81%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  <doc>               :  5810 ocurrencias\n",
      "  <pat>               :  4895 ocurrencias\n",
      "  guest_family        :   560 ocurrencias\n",
      "  guest_clinician     :   119 ocurrencias\n",
      "  ma'am               :   116 ocurrencias\n",
      "  i'd                 :    91 ocurrencias\n",
      "  let's               :    65 ocurrencias\n",
      "  what's              :    57 ocurrencias\n",
      "  haven't             :    45 ocurrencias\n",
      "  i'll                :    44 ocurrencias\n",
      "\n",
      "TABLA COMPARATIVA DE COBERTURA\n",
      "                Modelo  Cobertura Vocabulario (%)  Cobertura Tokens (%)  Palabras Encontradas  Palabras No Encontradas\n",
      "Word2Vec (Google News)                      94.75                 71.68                  5085                      282\n",
      " GloVe (Wiki Gigaword)                      94.24                 91.89                  5058                      309\n",
      "  FastText (Wiki News)                      94.75                 91.81                  5085                      282\n"
     ]
    }
   ],
   "source": [
    "# Obtener vocabulario del dataset\n",
    "all_tokens = []\n",
    "for text in df['dialog_clean']:\n",
    "    if pd.notna(text):\n",
    "        all_tokens.extend(text.split())\n",
    "\n",
    "vocab = set(all_tokens)\n",
    "vocab_freq = Counter(all_tokens)\n",
    "\n",
    "print(f\"Total de palabras/tokens: {len(all_tokens):,}\")\n",
    "print(f\"\\nVocabulario total: {len(vocab):,} palabras/tokens únic@s\")\n",
    "\n",
    "\n",
    "# Análisis para cada modelo\n",
    "models = {\n",
    "    'Word2Vec (Google News)': w2v,\n",
    "    'GloVe (Wiki Gigaword)': glove,\n",
    "    'FastText (Wiki News)': ft\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    \n",
    "    found_words = [w for w in vocab if w in model.key_to_index]\n",
    "    missing_words = [w for w in vocab if w not in model.key_to_index]\n",
    "    \n",
    "    found_tokens = sum(vocab_freq[w] for w in found_words)\n",
    "    total_tokens = sum(vocab_freq.values())\n",
    "    \n",
    "    coverage_vocab = len(found_words) / len(vocab) * 100\n",
    "    coverage_tokens = found_tokens / total_tokens * 100\n",
    "    \n",
    "    print(f\"Palabras encontradas: {len(found_words):,}/{len(vocab):,} ({coverage_vocab:.2f}%)\")\n",
    "    print(f\"Tokens cubiertos: {found_tokens:,}/{total_tokens:,} ({coverage_tokens:.2f}%)\")\n",
    "    \n",
    "    missing_freq = {w: vocab_freq[w] for w in missing_words}\n",
    "    top_missing = sorted(missing_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(f\"\\nTop 10 palabras NO encontradas (más frecuentes):\")\n",
    "    for word, freq in top_missing:\n",
    "        print(f\"  {word:20s}: {freq:5d} ocurrencias\")\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Cobertura Vocabulario (%)': round(coverage_vocab, 2),\n",
    "        'Cobertura Tokens (%)': round(coverage_tokens, 2),\n",
    "        'Palabras Encontradas': len(found_words),\n",
    "        'Palabras No Encontradas': len(missing_words)\n",
    "    })\n",
    "\n",
    "# Tabla comparativa\n",
    "print(\"\\nTABLA COMPARATIVA DE COBERTURA\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a4ac8",
   "metadata": {},
   "source": [
    "CON LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16ac6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras/tokens en todas las conversaciones ORIGINALMENTE: 126935\n",
      "Total de tokens: 126,935\n",
      "\n",
      "Vocabulario total: 9,496 palabras/tokens únic@s\n",
      "\n",
      "Modelo: Word2Vec (Google News)\n",
      "Palabras encontradas: 4,766/9,496 (50.19%)\n",
      "Tokens cubiertos: 86,784/126,935 (68.37%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  Doctor:             :  5809 ocurrencias\n",
      "  Patient:            :  4895 ocurrencias\n",
      "  to                  :  2077 ocurrencias\n",
      "  a                   :  1983 ocurrencias\n",
      "  and                 :  1822 ocurrencias\n",
      "  of                  :  1567 ocurrencias\n",
      "  Guest_family:       :   559 ocurrencias\n",
      "  Yes,                :   518 ocurrencias\n",
      "  No,                 :   477 ocurrencias\n",
      "  Yeah,               :   302 ocurrencias\n",
      "\n",
      "Modelo: GloVe (Wiki Gigaword)\n",
      "Palabras encontradas: 3,941/9,496 (41.50%)\n",
      "Tokens cubiertos: 75,535/126,935 (59.51%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  Doctor:             :  5809 ocurrencias\n",
      "  Patient:            :  4895 ocurrencias\n",
      "  I                   :  4720 ocurrencias\n",
      "  Do                  :   648 ocurrencias\n",
      "  How                 :   581 ocurrencias\n",
      "  Guest_family:       :   559 ocurrencias\n",
      "  Yes,                :   518 ocurrencias\n",
      "  What                :   507 ocurrencias\n",
      "  No,                 :   477 ocurrencias\n",
      "  No.                 :   443 ocurrencias\n",
      "\n",
      "Modelo: FastText (Wiki News)\n",
      "Palabras encontradas: 5,763/9,496 (60.69%)\n",
      "Tokens cubiertos: 98,890/126,935 (77.91%)\n",
      "\n",
      "Top 10 palabras NO encontradas (más frecuentes):\n",
      "  Doctor:             :  5809 ocurrencias\n",
      "  Patient:            :  4895 ocurrencias\n",
      "  Guest_family:       :   559 ocurrencias\n",
      "  Yes,                :   518 ocurrencias\n",
      "  No,                 :   477 ocurrencias\n",
      "  I'm                 :   441 ocurrencias\n",
      "  don't               :   310 ocurrencias\n",
      "  Yeah,               :   302 ocurrencias\n",
      "  Well,               :   256 ocurrencias\n",
      "  it's                :   249 ocurrencias\n",
      "\n",
      "TABLA COMPARATIVA DE COBERTURA\n",
      "                Modelo  Cobertura Vocabulario (%)  Cobertura Tokens (%)  Palabras Encontradas  Palabras No Encontradas\n",
      "Word2Vec (Google News)                      50.19                 68.37                  4766                     4730\n",
      " GloVe (Wiki Gigaword)                      41.50                 59.51                  3941                     5555\n",
      "  FastText (Wiki News)                      60.69                 77.91                  5763                     3733\n"
     ]
    }
   ],
   "source": [
    "# Obtener vocabulario del dataset\n",
    "all_tokens = []\n",
    "for text in df['dialogue']:\n",
    "    if pd.notna(text):\n",
    "        all_tokens.extend(text.split())\n",
    "\n",
    "vocab = set(all_tokens)\n",
    "vocab_freq = Counter(all_tokens)\n",
    "\n",
    "total_palabras = df['dialogue'].apply(lambda x: len(str(x).split())).sum()\n",
    "print(f\"Total de palabras/tokens en todas las conversaciones ORIGINALMENTE: {total_palabras}\")\n",
    "\n",
    "print(f\"Total de tokens: {len(all_tokens):,}\")\n",
    "print(f\"\\nVocabulario total: {len(vocab):,} palabras/tokens únic@s\")\n",
    "\n",
    "\n",
    "# Análisis para cada modelo\n",
    "models = {\n",
    "    'Word2Vec (Google News)': w2v,\n",
    "    'GloVe (Wiki Gigaword)': glove,\n",
    "    'FastText (Wiki News)': ft\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    \n",
    "    found_words = [w for w in vocab if w in model.key_to_index]\n",
    "    missing_words = [w for w in vocab if w not in model.key_to_index]\n",
    "    \n",
    "    found_tokens = sum(vocab_freq[w] for w in found_words)\n",
    "    total_tokens = sum(vocab_freq.values())\n",
    "    \n",
    "    coverage_vocab = len(found_words) / len(vocab) * 100\n",
    "    coverage_tokens = found_tokens / total_tokens * 100\n",
    "    \n",
    "    print(f\"Palabras encontradas: {len(found_words):,}/{len(vocab):,} ({coverage_vocab:.2f}%)\")\n",
    "    print(f\"Tokens cubiertos: {found_tokens:,}/{total_tokens:,} ({coverage_tokens:.2f}%)\")\n",
    "    \n",
    "    missing_freq = {w: vocab_freq[w] for w in missing_words}\n",
    "    top_missing = sorted(missing_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(f\"\\nTop 10 palabras NO encontradas (más frecuentes):\")\n",
    "    for word, freq in top_missing:\n",
    "        print(f\"  {word:20s}: {freq:5d} ocurrencias\")\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Cobertura Vocabulario (%)': round(coverage_vocab, 2),\n",
    "        'Cobertura Tokens (%)': round(coverage_tokens, 2),\n",
    "        'Palabras Encontradas': len(found_words),\n",
    "        'Palabras No Encontradas': len(missing_words)\n",
    "    })\n",
    "\n",
    "# Tabla comparativa\n",
    "print(\"\\nTABLA COMPARATIVA DE COBERTURA\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b807607",
   "metadata": {},
   "source": [
    "SI USAMOS EL SEPARADOR DE DIALOGUE CLEAN, SE GENERAN 26000 TOKENS MÁS  AL SEPARAR LOS SIGNOS DE PUNTUACION, PERO EL % DE COBERTURA DE TOKENS PASA DE 68-69-77 A 71-98-98% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c92f7b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
