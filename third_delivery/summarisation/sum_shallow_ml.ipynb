{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863f2b81",
   "metadata": {},
   "source": [
    "# 1. Introducción y Preparación del Entorno\n",
    "En esta aproximación al problema de **Summarization**, utilizaremos técnicas de **Shallow Learning**.\n",
    "\n",
    "Vamos a utilizar técnicas de **Sparse Representations**. A diferencia de los modelos de Deep Learning que generan texto nuevo palabra por palabra, aquí nos centraremos en **Extractive Summarization**: seleccionar las frases más relevantes del diálogo original y concatenarlas para formar un resumen.\n",
    "\n",
    "**Decisiones de Diseño:**\n",
    "* **Dataset:** Utilizamos el set de entrenamiento de \"MTS-Dialog\".\n",
    "* **Preprocesamiento:** Para esta tarea, la unidad mínima de información no es el token, sino la sentence. Usamos \"sent_tokenize\" de NLTK en lugar de dividir por puntos simples para manejar mejor las abreviaturas médicas (por ejemplo, \"Dr.\" o \"Mr.\") y evitar cortes erróneos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e034616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Iker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge-score in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (2.2.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\iker\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Datos cargados. Ejemplo de diálogo:\n",
      "Doctor: What brings you back into the clinic today, miss? \n",
      "Patient: I came in for a refill of my blood pressure medicine. \n",
      "Doctor: It looks like Doctor Kumar followed up with you last time regarding...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('punkt')\n",
    "!pip install rouge-score\n",
    "\n",
    "# Cargar datos\n",
    "df_train = pd.read_csv(\"../../dataset/MTS-Dialog-TrainingSet.csv\")\n",
    "df_sample = df_train.head(100).copy() \n",
    "\n",
    "print(\"Datos cargados. Ejemplo de diálogo:\")\n",
    "print(df_sample['dialogue'].iloc[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba4033",
   "metadata": {},
   "source": [
    "# 2. Técnica 1: Resumen basado en Frecuencia (TF-IDF)\n",
    "Nuestra primera técnica utiliza **TF-IDF** como medida de importancia.\n",
    "\n",
    "**Hipótesis:**\n",
    "En un diálogo médico, las palabras más informativas son aquellas que son específicas del caso (\"diabetes\", \"ibuprofeno\", \"cirugía\") y no las palabras comunes de relleno (\"hola\", \"bueno\", \"entonces\").\n",
    "\n",
    "**Metodología:**\n",
    "1.  Convertimos el diálogo en una matriz TF-IDF dispersa.\n",
    "2.  Calculamos el score de cada frase sumando los valores TF-IDF de las palabras que contiene.\n",
    "3.  Seleccionamos las N frases con mayor puntuación acumulada.\n",
    "\n",
    "TF-IDF genera vectores de alta dimensionalidad con muchos ceros, ignorando el orden semántico profundo pero capturando palabras clave críticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f04da149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen TF-IDF generado para el primer ejemplo:\n",
      "Doctor: It looks like Doctor Kumar followed up with you last time regarding your hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones. Doctor: Have you had any fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure?\n"
     ]
    }
   ],
   "source": [
    "def summarize_tfidf(text, num_sentences=2):\n",
    "    # 1. Dividir en frases\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return text\n",
    "    \n",
    "    # 2. Calcular TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    except ValueError: # Caso textos vacíos\n",
    "        return text\n",
    "        \n",
    "    # 3. Sumar scores por frase\n",
    "    sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)\n",
    "    \n",
    "    # 4. Ordenar y elegir las top N frases\n",
    "    top_indices = np.argsort(sentence_scores)[-num_sentences:]\n",
    "    top_indices = sorted(top_indices) # Reordenar para mantener flujo original\n",
    "    \n",
    "    summary = \" \".join([sentences[i] for i in top_indices])\n",
    "    return summary\n",
    "\n",
    "# Aplicar al dataset\n",
    "df_train['pred_tfidf'] = df_train['dialogue'].apply(lambda x: summarize_tfidf(str(x)))\n",
    "print(\"Resumen TF-IDF generado para el primer ejemplo:\")\n",
    "print(df_train['pred_tfidf'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5846b63",
   "metadata": {},
   "source": [
    "# 3. Técnica 2: Resumen basado en Grafos (TextRank)\n",
    "Como segunda técnica de Shallow Learning, implementamos **TextRank**, un algoritmo no supervisado inspirado en PageRank.\n",
    "\n",
    "**Justificación y Diferencias:**\n",
    "A diferencia de TF-IDF, que mira palabras aisladas, TextRank considera la \"relación entre frases\".\n",
    "* Modelamos el texto como un grafo donde los nodos son las oraciones.\n",
    "* Las conexiones representan la cosine-similarity entre los vectores TF-IDF de las oraciones.\n",
    "\n",
    "**Hipótesis:**\n",
    "Las oraciones más importantes no son necesariamente las que tienen palabras raras (como en TF-IDF), sino las que son más representativas del contenido global del diálogo (aquellas que se parecen más al resto de las oraciones). Esto debería producir resúmenes más cohesivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f08be008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen TextRank generado.\n"
     ]
    }
   ],
   "source": [
    "def summarize_textrank(text, num_sentences=2):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return text\n",
    "\n",
    "    # 1. Crear matriz de similaridad entre frases (usando TF-IDF features)\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    except ValueError:\n",
    "        return text\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # 2. Crear grafo y calcular PageRank\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # 3. Ordenar por puntuación\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    \n",
    "    # 4. Seleccionar top frases\n",
    "    summary = \" \".join([s for score, s in ranked_sentences[:num_sentences]])\n",
    "    return summary\n",
    "\n",
    "# Aplicar al dataset\n",
    "df_train['pred_textrank'] = df_train['dialogue'].apply(lambda x: summarize_textrank(str(x)))\n",
    "print(\"Resumen TextRank generado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad8184",
   "metadata": {},
   "source": [
    "# 4. Evaluación Comparativa (Métricas ROUGE)\n",
    "Para evaluar la calidad de los resúmenes, no vamos a usar \"Accuracy\". Utilizamos ROUGE, que es el estándar en NLP para esta tarea.\n",
    "\n",
    "* **ROUGE-1:** Mide la coincidencia de unigramas (palabras individuales). Evalúa la cobertura de contenido, es decir, si se mencionan las palabras clave.\n",
    "* **ROUGE-L:** Mide la subsecuencia común más larga. Evalúa la fluidez y estructura a nivel de frase.\n",
    "\n",
    "**Nota sobre los Resultados Esperados:**\n",
    "Esperamos puntuaciones bajas (entorno a 0.15 - 0.25) debido a la naturaleza del problema:\n",
    "1.  **Gap Extractivo vs Abstractivo:** Estamos intentando reconstruir una nota clínica formal recortando frases de un diálogo informal.\n",
    "2.  **Penalización:** ROUGE penaliza severamente si no usamos las palabras exactas. Si el paciente dice \"me duele la tripa\" y el médico anota \"dolor abdominal\", nuestros modelos de Shallow Learning fallarán en capturar esa relación, bajando el score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fe7f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados Shallow ML 1: TF-IDF ---\n",
      "{'rouge1': np.float64(0.20246636087274483), 'rougeL': np.float64(0.16167682145568624)}\n",
      "\n",
      "--- Resultados Shallow ML 2: TextRank ---\n",
      "{'rouge1': np.float64(0.10599440719873192), 'rougeL': np.float64(0.08904900648066023)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def calculate_scores(preds, refs):\n",
    "    scores = {'rouge1': [], 'rougeL': []}\n",
    "    for p, r in zip(preds, refs):\n",
    "        score = scorer.score(str(r), str(p))\n",
    "        scores['rouge1'].append(score['rouge1'].fmeasure)\n",
    "        scores['rougeL'].append(score['rougeL'].fmeasure)\n",
    "    return {k: np.mean(v) for k, v in scores.items()}\n",
    "\n",
    "# Evaluar TF-IDF\n",
    "scores_tfidf = calculate_scores(df_train['pred_tfidf'], df_train['section_text'])\n",
    "print(\"--- Resultados Shallow ML 1: TF-IDF ---\")\n",
    "print(scores_tfidf)\n",
    "\n",
    "# Evaluar TextRank\n",
    "scores_textrank = calculate_scores(df_train['pred_textrank'], df_train['section_text'])\n",
    "print(\"\\n--- Resultados Shallow ML 2: TextRank ---\")\n",
    "print(scores_textrank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22738fbb",
   "metadata": {},
   "source": [
    "## Análisis de Resultados (Shallow Learning)\n",
    "\n",
    "Se puede ver una clara superioridad de TF-IDF sobre TextRank.\n",
    "\n",
    "**Justificación Técnica:**\n",
    "1.  **Alineación Semántica:** TF-IDF premia términos específicos que tienen alta carga informativa y suelen aparecer tal cual en el resumen médico.\n",
    "2.  **Fallo de TextRank:** Al basarse en grafos de similitud, TextRank creemos que confunde frases estructurales o de \"relleno\" (saludos, confirmaciones) como las más importantes por su centralidad en el diálogo, introduciendo ruido.\n",
    "3.  **Limitación Extractiva:** Ambos modelos tienen un techo de rendimiento bajo porque no pueden parafrasear. Como hemos mencionado anteriormente, si el paciente dice \"dolor de tripa\" y el médico escribe \"dolor abdominal\", estos modelos fallan al buscar coincidencia exacta, lo que justifica cambiar a metodos de DL mas avanzados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
