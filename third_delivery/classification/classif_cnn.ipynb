{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f1b0b5",
   "metadata": {},
   "source": [
    "De cara a hacer uso del DEEP LEARNING en una tarea de clasificación, planeamos fine tunear un fork de BERT, entrenado con conversaciones clinicas. En nuestro caso, planeamos fine-tunear ese modelo con nuestras conversaciones, evaluarlo, y finalmente usarlo en inferencia para clasificar conversaciones de la validation set y preparar un script para clasificar textos escritos por nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7df06",
   "metadata": {},
   "source": [
    "## PRIMER APPROACH: Fine‑tune Bio_ClinicalBERT (classification head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b448da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d674db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga del dataset\n",
    "df = pd.read_csv(\"../../dataset/MTS-Dialog-TrainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ca575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesamiento para BERT\n",
    "def normalize_for_bert(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = re.sub(r'\\b(Doctor|Doctor_2|Patient|Guest_family(_\\d)?|Guest_clinician)[:\\-]\\s*', '', s, flags=re.I)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "df['text_for_bert'] = df['dialogue'].apply(normalize_for_bert)\n",
    "\n",
    "\n",
    "X = df['text_for_bert']\n",
    "y = df['section_header']\n",
    "\n",
    "# Encode \n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga del tokenizer y modelo\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(le.classes_),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "# Tokenización\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa334b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_dataset = Dataset.from_dict({'text': X_train.tolist(), 'label': y_train.tolist()})\n",
    "test_dataset = Dataset.from_dict({'text': X_test.tolist(), 'label': y_test.tolist()})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751103a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de evaluación\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807fac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración del entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_clinicalbert',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    seed=42,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9729c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 960/960 [00:00<00:00, 3864.05 examples/s]\n",
      "Map: 100%|██████████| 241/241 [00:00<00:00, 3535.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.931700</td>\n",
       "      <td>1.643910</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.262969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.277400</td>\n",
       "      <td>1.200764</td>\n",
       "      <td>0.759336</td>\n",
       "      <td>0.339809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.106800</td>\n",
       "      <td>1.117554</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.345453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1175535917282104, 'eval_accuracy': 0.7717842323651453, 'eval_f1_macro': 0.34545303347045025, 'eval_runtime': 1.8796, 'eval_samples_per_second': 128.218, 'eval_steps_per_second': 16.493, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune\n",
    "trainer.train()\n",
    "\n",
    "# Evaluación\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "# Guardar modelo\n",
    "model.save_pretrained('./finetuned_clinicalbert')\n",
    "tokenizer.save_pretrained('./finetuned_clinicalbert')\n",
    "\n",
    "# Guardar encoder de labels\n",
    "import pickle\n",
    "with open('./finetuned_clinicalbert/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0fea3",
   "metadata": {},
   "source": [
    "Las métricas no son muy visibles en el output, por lo que las adjuntamos a continuación:\n",
    "\n",
    "'eval_loss': 1.1175535917282104, \n",
    "\n",
    "'eval_accuracy': 0.7717842323651453, \n",
    "\n",
    "'eval_f1_macro': 0.34545303347045025, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490112f4",
   "metadata": {},
   "source": [
    "El accuracy es bueno como esperabamos de una red neuronal convolucional, el training loss ha disminuido drasticamente por cada pasada del dataset (epoch), lo que indica que un entrenamiento más largo podría contribuir a un fine-tunning más eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdd481",
   "metadata": {},
   "source": [
    "Ahora, ya que hemos guardado el modelo, procedemos a usarlo en inferencia, ya que es interesante ver nuestro modelo en acción fuera de los números y las métricas de accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f8300",
   "metadata": {},
   "source": [
    "INFERENCE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9247ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: GENHX | Confidence: 0.924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import pickle\n",
    "import re, unicodedata\n",
    "\n",
    "# Minimal preprocessing (same as training)\n",
    "def normalize_for_bert(s):\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
    "    s = re.sub(r'\\b(Doctor|Doctor_2|Patient|Guest_family(_\\d)?|Guest_clinician)[:\\-]\\s*', '', s, flags=re.I)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# Load label encoder and model\n",
    "with open('./finetuned_clinicalbert/label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"./finetuned_clinicalbert\",\n",
    "    tokenizer=\"./finetuned_clinicalbert\",\n",
    "    device=0  # use -1 for CPU\n",
    ")\n",
    "\n",
    "# Load a validation sample\n",
    "df_val = pd.read_csv(\"../../dataset/MTS-Dialog-ValidationSet.csv\")\n",
    "text = normalize_for_bert(df_val.loc[0, \"dialogue\"])  # any row from validation set\n",
    "\n",
    "# Predict\n",
    "out = clf(text)[0]\n",
    "pred_label = le.inverse_transform([int(out['label'].split('_')[-1])])[0]\n",
    "print(f\"Predicted: {pred_label} | Confidence: {out['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f167ca",
   "metadata": {},
   "source": [
    "El modelo clasifica el primer texto del dataset de validación en GENHX con una confianza del 0.924, lo cual es correcto. Este hecho es muy interesante y bastante sorprendente dada la poca cantidad de epochs con los que lo hemos entrenado y la gran confianza con la que lo clasifica en esa clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0debb",
   "metadata": {},
   "source": [
    "En caso de querer clasificar un texto proporcionado por nosotros, podemos hacer uso del siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: FAM/SOCHX, Confidence: 0.138\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Patient reports chest pain for 3 days...\"\n",
    "result = classifier(sample_text)\n",
    "predicted_label = le.inverse_transform([int(result[0]['label'].split('_')[-1])])[0]\n",
    "print(f\"Predicted: {predicted_label}, Confidence: {result[0]['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e636c",
   "metadata": {},
   "source": [
    "Está claro que el texto proporcionado es demasiado corto y le falta procesamiento, pero serviria en caso de introducir un texto más acorde al entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
